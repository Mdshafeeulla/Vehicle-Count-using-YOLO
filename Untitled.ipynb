{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "195ca670-01a2-4274-90c9-7347953e4e51",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import cvzone\n",
    "import math\n",
    "from sort import *\n",
    "\n",
    "#If we want we can use the camera also \n",
    "# cap = cv2.VideoCapture(0)\n",
    "\n",
    "#We need to take the same height and width for mask and the image or else we cant perform bitwise operation\n",
    "display_width = 1280\n",
    "display_height = 720\n",
    "\n",
    "#Setting up the path for the video\n",
    "cap = cv2.VideoCapture('./traffic.mp4')\n",
    "mask = cv2.imread('./mask.png')\n",
    "mask = cv2.resize(mask,(display_width,display_height))\n",
    "\n",
    "#Tracking the image for counting out the vehicles\n",
    "tracker = Sort(max_age = 20, min_hits = 3, iou_threshold = 0.3)\n",
    "\n",
    "#After the cars cross this line the will be counted\n",
    "limits = [350,397,1150,397]\n",
    "total_count = []\n",
    "\n",
    "#This are the classes that yolo can define by seeing\n",
    "classes = [\"person\", \"bicycle\", \"car\", \"motorbike\", \"aeroplane\", \"bus\", \"train\", \"truck\", \"boat\",\"traffic light\", \"fire hydrant\", \"stop sign\", \"parking meter\", \"bench\", \"bird\", \"cat\",\n",
    "\"dog\", \"horse\", \"sheep\", \"cow\", \"elephant\", \"bear\", \"zebra\", \"giraffe\", \"backpack\", \"umbrella\",\"handbag\",\"tie\", \"suitcase\", \"frisbee\", \"skis\", \"spowboard\", \"sports ball\", \"kite\", \"baseball bat\",\n",
    "\"baseball glove\", \"skateboard\", \"surfboard\", \"tennis racket\", \"bottle\", \"wine glass\", \"cup\",\"fork\", \"knife\", \"spoon\", \"bowl\", \"banana\", \"apple\", \"sandwich\", \"orange\", \"broccoli\",\n",
    "\"carrot\", \"hot dog\", \"pizza\", \"donut\", \"cake\", \"chair\", \"sofa\", \"pottedplant\", \"bed\",\"diningtable\", \"toilet\", \"tvmonitor\", \"laptop\", \"mouse\", \"remote\", \"keyboard\", \"cell phone\",\n",
    "\"microwave\", \"oven\", \"toaster\", \"sink\", \"refrigerator\", \"book\", \"clock\", \"vase\", \"scissors\",\"teddy bear\", \"hair drier\", \"toothbrush\"]\n",
    "\n",
    "#Pre trained YOLO model here we are using the large model\n",
    "model = YOLO('./yolo_weights/yolov8l.pt')\n",
    "\n",
    "#Looping the video \n",
    "while True:\n",
    "    success, img = cap.read()\n",
    "    img = cv2.resize(img,(display_width,display_height))\n",
    "    \n",
    "#The reason for using cv2.bitwise_and is to focus detection only on the region of interest, which helps prevent \n",
    "#unnecessary counting of vehicles outside the relevant area and reduces computation on irrelevant objects that \n",
    "#don't provide useful insights for this task.\n",
    "    img_region = cv2.bitwise_and(img,mask)\n",
    "    results = model(img_region,stream = True)\n",
    "\n",
    "    detections = np.empty((0, 5))\n",
    "    #This is used to create the bounding boxes\n",
    "    for r in results:\n",
    "        boxes = r.boxes\n",
    "        for box in boxes:\n",
    "            x1,y1,x2,y2 = box.xyxy[0]\n",
    "            x1,y1,x2,y2 = int(x1),int(y1),int(x2),int(y2)\n",
    "            w,h = x2-x1,y2-y1\n",
    "            \n",
    "            #This is used to show the confidence interval\n",
    "            conf = math.ceil((box.conf[0]*100))/100\n",
    "            print(conf)\n",
    "            \n",
    "            #This is used to show which object it is\n",
    "            cls = int(box.cls[0])\n",
    "            name = classes[cls]\n",
    "            if name == 'car' or name == 'bicycle' or name == 'motorbike' or name == 'bus' or  name == 'truck' or name == 'stop sign' and conf > 0.3 :\n",
    "                # cvzone.putTextRect(img,f'{name}:{conf}',(max(0,x1),max(35,y1)),scale = 0.7,thickness = 1,offset = 2)\n",
    "                # cvzone.cornerRect(img,(x1,y1,w,h),l=8)\n",
    "                \n",
    "                currentArray = np.array([x1,y1,x2,y2,conf])\n",
    "                detections = np.vstack((detections,currentArray))\n",
    "\n",
    "    \n",
    "    resultsTracker = tracker.update(detections)   \n",
    "    cv2.line(img, (limits[0],limits[1]),(limits[2],limits[3]),(0,0,255),3)\n",
    "\n",
    "    for result in resultsTracker:\n",
    "        x1, y1, x2, y2, Id = result\n",
    "        x1,y1,x2,y2 = int(x1),int(y1),int(x2),int(y2)   \n",
    "        print(result)\n",
    "        w,h = x2-x1,y2-y1\n",
    "        cvzone.cornerRect(img, (x1,y1,w,h),l=9, rt = 2, colorR=(255,0,0))        \n",
    "        cvzone.putTextRect(img,f'{int(Id)}',(max(0,x1),max(35,y1)),scale = 0.7,thickness = 1,offset = 10)\n",
    "\n",
    "        cx,cy = x1 + w//2,y1 + h//2\n",
    "        cv2.circle(img,(cx,cy),5,(2,0,25),cv2.FILLED)\n",
    "        #Counting the number of vehicles passed\n",
    "        if limits[0] < cx < limits[2] and limits[1] - 15 < cy < limits[1] + 15:\n",
    "            if total_count.count(Id) == 0:\n",
    "                total_count.append(Id)\n",
    "                cv2.line(img, (limits[0],limits[1]),(limits[2],limits[3]),(255,0,255),3)\n",
    "                                \n",
    "    cvzone.putTextRect(img,f'count : {len(total_count)}',(50,50))\n",
    "        \n",
    "    cv2.imshow(\"Image\",img)\n",
    "    cv2.waitKey(1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f73fe9-dad2-4ff8-9b28-c71724cb6698",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b2d61c-8bde-46ab-9bef-8311e5336a8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5676b7ae-6128-4d30-b4e7-cd930f45fd9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ae7880-418f-4db0-9c33-e8a6fff4609b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
